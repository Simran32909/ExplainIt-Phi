transformers>=4.36.2
accelerate>=0.26.1
datasets>=2.16.1
bitsandbytes>=0.42.0
peft>=0.7.1
llama-cpp-python>=0.2.20
jupyter
gradio>=4.16.0
wandb>=0.16.2
hydra-core>=1.3.2
omegaconf>=2.3.0
pytorch-lightning>=2.1.3
torch>=2.1.2
flash-attn>=2.4.2
einops
scipy
tqdm 